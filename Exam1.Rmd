---
title: "OMIS 482 - Fall 2024"
lang: en-US
output:
  examinr::exam_document:
    id: Exam1
    version: 0.1
    order: fixed
runtime: shiny_prerendered
---



```{r setup, include=FALSE}
# Set a CRAN mirror
options(repos = c(CRAN = "https://cloud.r-project.org"))

#Uncomment if the packages are not installed
#install.packages("googlesheets4")
#install.packages("dplyr") # for data manipulation
#install.packages("rsconnect")
library(examinr)
library(rsconnect)
library(googlesheets4)
library(base64enc)
library(rlang)
library(uuid)
library(dplyr)
library(shiny)
library(tidyverse)
library(nycflights13)
set.seed(0101)
flights <- sample_n(flights, 15000)

knitr::opts_chunk$set(echo = FALSE)


```


```{r,context='server-start'}

# Path to your service account JSON key file
json_path <- "dr-b-dashboard-project.json"

# Authenticate with Google Sheets using the service account key
gs4_auth(path = json_path)


# Google Sheets IDs
sheet_id <- "1se2CvGntBc5vWgJR-CrXGLYXR69NhGrE7vewmxScB1A"

# Function to read user data from Google Sheets
get_user_data <- function(sheet_id) {
  users <- read_sheet(sheet_id, sheet = "users")
  return(users)
}

# Get user data
users <- get_user_data(sheet_id)

# Set up token-based authentication

auth_provider <- ui_token_auth(
  users = users,
  token_label = "Enter your Token-ID",
  title = "Login",
  button_label = "Login",
  token_empty = "Login cannot be empty.",
  unauthorized = "The Token-ID is incorrect."
)

# Use the ZID field instead of user_id for identifying users
users$ZID <- users$ZID  # Ensure that the ZID field is used properly

# Function to serialize and base64 encode an R object
serialize_object <- function(object) {
  if (is.null(object)) return(NA_character_)
  raw_obj <- serialize(object, NULL)
  base64enc::base64encode(raw_obj)
}

# Function to base64 decode and unserialize a string back to an R object
deserialize_object <- function(base64_string) {
  if (is.null(base64_string) || !is.character(base64_string)) return(NULL)
  raw_obj <- base64enc::base64decode(base64_string)
  unserialize(raw_obj)
}



# Create a new attempt
create_attempt <- function(user, exam_id, exam_version, seed, started_at, ...) {
  attempt_id <- UUIDgenerate()
  user_obj_serialized <- serialize_object(user)
  row <- data.frame(
    attempt_id = attempt_id,
    user_id = user$user_id,
    exam_id = exam_id,
    exam_version = exam_version,
    user_obj = user_obj_serialized,
    seed = seed,
    started_at = format(started_at, "%Y-%m-%d %H:%M:%S"),
    finished_at = NA,
    points = NA
  )
  # Append the row to Google Sheets
  sheet_append(sheet_id, row, sheet = "attempts")
  return(attempt_id)
}


# Finish an attempt
finish_attempt <- function(attempt_id, finished_at, ...) {
  # Convert finished_at to POSIXct and format it
  finished_at_formatted <- format(as.POSIXct(finished_at), "%Y-%m-%d %H:%M:%S")
  
  # Read the current attempts from Google Sheets
  attempts <- read_sheet(sheet_id, sheet = "attempts")
  
  # Update the finished_at field for the specific attempt_id
  attempts <- attempts %>% 
    mutate(finished_at = ifelse(attempt_id == !!attempt_id, finished_at_formatted, finished_at))
  
  # Write the updated data back to Google Sheets
  sheet_write(attempts, sheet_id, sheet = "attempts")
  
  return(TRUE)
}


# Grade an attempt
grade_attempt <- function(attempt_id, points, ...) {
  attempts <- read_sheet(sheet_id, sheet = "attempts")
  
  # Ensure points are serialized and base64 encoded
  serialized_points <- tryCatch(
    serialize_object(points),
    error = function(e) {
      warning("Failed to serialize points: ", e$message)
      return(NA)
    }
  )
  
  if (is.na(serialized_points)) {
    return(FALSE) # Do not proceed if serialization fails
  }

  # Ensure the data size does not exceed the limit
  if (nchar(serialized_points) > 50000) {
    warning("Serialized points data exceeds the maximum size limit.")
    return(FALSE)
  }

  attempts <- attempts %>% 
    mutate(points = ifelse(attempt_id == !!attempt_id, serialized_points, points))

  sheet_write(attempts, sheet_id, sheet = "attempts")
  return(TRUE)
}

# Get attempts
get_attempts <- function(user, exam_id, exam_version, ...) {
  attempts <- read_sheet(sheet_id, sheet = "attempts")
  attempts$user_obj <- lapply(attempts$user_obj, function(x) {
    if (!is.na(x) && nchar(x) > 0) {
      deserialize_object(x)
    } else {
      NULL
    }
  })

  if (!is.null(user)) {
    attempts <- attempts[attempts$user_id == user$user_id, , drop = FALSE]
  }
  if (!is.null(exam_id)) {
    attempts <- attempts[attempts$exam_id == exam_id, , drop = FALSE]
  }
  if (!is.null(exam_version)) {
    attempts <- attempts[attempts$exam_version == exam_version, , drop = FALSE]
  }

  return(attempts)
}


# Save section data
save_section_data <- function(attempt_id, section, section_data, ...) {
  # Read existing section data
  existing_data <- read_sheet(sheet_id, sheet = "section_data")

  # Determine the next ID
  if (nrow(existing_data) == 0) {
    next_id <- 1
  } else {
    existing_ids <- as.numeric(existing_data$id)
    next_id <- max(existing_ids, na.rm = TRUE) + 1
  }

  # Create a new row with the next ID and other data
  row <- tibble(
    id = next_id,
    attempt_id = attempt_id,
    section = section,
    timestamp = as.character(Sys.time()),
    section_data = serialize_object(section_data)
  )

  # Append the new row to the Google Sheet
  sheet_append(sheet_id, data = row, sheet = "section_data")
  return(TRUE)
}



# Get section data
get_section_data <- function(attempt_id, section, ...) {
  section_data <- read_sheet(sheet_id, sheet = "section_data")
  section_data <- section_data %>% filter(attempt_id == !!attempt_id)
  
  if (!is.null(section)) {
    section_data <- section_data %>% filter(section == section)
  }
  section_data <- section_data %>%
    rowwise() %>%
    mutate(section_data = list(deserialize_object(section_data))) %>%
    ungroup()
  return(split(section_data, seq(nrow(section_data))))
}

# Get the last section for an attempt
get_last_section <- function(attempt_id, ...) {
  section_data <- read_sheet(sheet_id, sheet = "section_data")
  section_data <- section_data %>% filter(attempt_id == !!attempt_id)
  if (nrow(section_data) > 0) {
    last_section <- section_data$section[which.max(section_data$timestamp)]
    return(last_section)
  }
  return(NULL)
}

# Combine all functions into a storage provider list
google_sheets_storage_provider <- list(
  create_attempt = create_attempt,
  finish_attempt = finish_attempt,
  grade_attempt = grade_attempt,
  get_attempts = get_attempts,
  save_section_data = save_section_data,
  get_section_data = get_section_data,
  get_last_section = get_last_section
)

# Use this Google Sheets storage provider for the exam
exam_config(auth_provider = auth_provider, storage_provider = google_sheets_storage_provider)




```


# Manipulation Review

# Use 'flights' dataset to answer the questions.

Only submit the Exam once you have completed it.

1. Write the code to show just the column names in the `flights` dataset.

```{r q-1, exercise=TRUE, exercise.autocomplete=TRUE,exercise.points=1, exercise.solution="q-1-solution"}


```

```{r q-1-solution, echo =FALSE}
colnames(flights)
```

2. Print the `flights` dataset in console

```{r q-2, exercise=TRUE,exercise.autocomplete=TRUE, exercise.points=1,  exercise.solution="q-2-solution"}


```

```{r q-2-solution, echo =FALSE}
flights
print(flights)
glimpse(flights)
```


3. Write the code to manipulate `flights` and only keep the observations that represent flights departed by `JFK` in the month of `August`

```{r q-3, exercise=TRUE, exercise.autocomplete=TRUE, exercise.points=1, exercise.solution="q-3-solution"}


```

```{r q-3-solution, echo =FALSE}
filter(flights, origin=="JFK" & month==8)#or
filter(flights, origin=="JFK" , month==8)#or
flights |> 
  filter(origin=="JFK" & month==8)
flights |> 
  filter(origin=="JFK" , month==8)
```

4. Write the code to create a column called `delay` that is equal to `arr_time`- `sched_arr_time`.  Make sure to show just the new computed column.

```{r q-4, exercise=TRUE, exercise.autocomplete=TRUE, exercise.points=1, exercise.solution="q-4-solution"}


```

```{r q-4-solution, echo = FALSE}
transmute(flights, delay=arr_time-sched_arr_time)#or
flights |> 
  transmute( delay=arr_time-sched_arr_time)
mutate(flights, delay=arr_time-sched_arr_time)#partially correct
flights |> 
  mutate( delay=arr_time-sched_arr_time)#partially correct
```

5. Write the code to compute the `average distance` of all the observations in the `flights` dataset.

```{r q-5, exercise=TRUE, exercise.autocomplete=TRUE, exercise.points=1, exercise.solution="q-5-solution"}


```

```{r q-5-solution, echo = FALSE}
summarise(flights, avg_distance= mean(distance))#or
summarise(flights, mean(distance, na.rm=T))#or
flights |> 
summarise( avg_distance= mean(distance))
```

6. Write the code to sort the `flights` dataset from the `largest air_time` to the `smallest air_time`.

```{r q-6, exercise=TRUE, exercise.autocomplete=TRUE,exercise.points=1, exercise.solution="q-6-solution"}


```

```{r q-6-solution, echo = FALSE}
arrange(flights, desc(air_time))#or
flights |> 
  arrange(desc(air_time))
```

7. Write the code to keep in the `flights` dataset only the columns that `end with` the word `time`.

```{r q-7, exercise=TRUE, exercise.autocomplete=TRUE,exercise.points=1, exercise.solution="q-7-solution"}


```

```{r q-7-solution, echo = FALSE}
select(flights, ends_with("time"))#or
flights |> 
  select( ends_with("time"))#or
select(flights, 4,5,7,8,15)
```

## Working with Pipes.[pipes are mandatory in this section]

8. Write the code to compute the `max air time` of the flights per each `dest`. Sort the data from the `largest max air time` to the `smallest max air time`.

```{r q-8, exercise=TRUE,exercise.autocomplete=TRUE, exercise.points=1,  exercise.solution="q-8-solution"}


```

```{r q-8-solution, echo = FALSE}
flights |> 
  group_by(dest) |> 
  summarise(max_air_time= max(air_time, na.rm = T)) |> 
  arrange(desc(max_air_time))

flights |> 
  group_by(dest) |> 
  summarise(max_air_time= max(air_time)) |> 
  arrange(desc(max_air_time))
```

9. Write the code to compute the `median arr_delay` of the flights per each `day of the year`. Sort the data from the `largest median arr_delay` to the `smallest median arr_delay`.

```{r q-9, exercise=TRUE, exercise.autocomplete=TRUE,exercise.points=1, exercise.solution="q-9-solution"}


```

```{r q-9-solution, echo = FALSE}
flights |> 
  group_by(year,month, day) |> 
  summarise(median_arr_delay= median(arr_delay, na.rm=T)) |> 
  arrange(desc(median_arr_delay))
```

10. Write the code to compute for each `carrier` the following:
     - `average distance`
     - `average arr_delay` (hint: exclude `NAs` if needed) 
     - `median distance`
     - `median arr_delay`
     - `sd distance` (hint: `sd` stands for standard deviation sd function) 
     - `sd arr_delay`
     - `number of flights` operated by each `carrier`

```{r q-10, exercise=TRUE, exercise.autocomplete=TRUE, exercise.points=1, exercise.solution="q-10-solution"}


```

```{r q-10-solution, echo = FALSE}
flights |> 
  group_by(carrier) |> 
  summarise(avg_distance= mean(distance),
            avg_arr_delay=mean(arr_delay, na.rm=T),
            median_distance=median(distance), 
            median_arr_delay= median(arr_delay, na.rm=T), 
            sd_distance=sd(distance), 
            sd_arr_delay=sd(arr_delay, na.rm = T), 
            number_flights=n())
```


11. Write the code to compute for each `destination` the following:
     - `average dep_delay`
     - `max dep_delay`
     - `median dep_delay`
     - `min dep_delay`
     - `sd dep_delay` 
     - `number of flights` landed at each `destination`
     - order the data from the `largest average dep_delay` to the `smallest average dep_delay` 
     - make sure only the observations with `sd smaller than 20` are kept in the dataset
     
```{r q-11, exercise=TRUE, exercise.autocomplete=TRUE, exercise.points=1, exercise.solution="q-11-solution"}


```

```{r q-11-solution, echo = FALSE}
flights |> 
  group_by(dest) |> 
  summarise(avg_dep_delay= mean(dep_delay,na.rm=T), 
            max_dep_delay=max(dep_delay, na.rm=T), 
            median_dep_delay= median(dep_delay, na.rm=T), 
            min_dep_delay=min(dep_delay, na.rm=T), 
            sd_dep_delay=sd(dep_delay, na.rm = T), number_flights=n()) |> 
  arrange(desc(avg_dep_delay)) |> 
  filter(sd_dep_delay<20)
```

# Done!

You have successfully submitted the Test.

